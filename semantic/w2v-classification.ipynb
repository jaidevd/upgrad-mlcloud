{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aerial-liver",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "honey-mixer",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load('data/imdb-word2vec.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "exterior-behavior",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import text_dataset_from_directory\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cutting-associate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25001 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Importing & preprocessing the dataset\n",
    "\n",
    "train_ds = text_dataset_from_directory('../neuralnets/aclImdb/train')\n",
    "test_ds = text_dataset_from_directory('../neuralnets/aclImdb/test')\n",
    "\n",
    "dfTrain = pd.DataFrame(train_ds.unbatch().as_numpy_iterator(), columns=['text', 'label'])\n",
    "dfTest = pd.DataFrame(test_ds.unbatch().as_numpy_iterator(), columns=['text', 'label'])\n",
    "_, xts = train_test_split(dfTest, stratify=dfTest['label'], test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "viral-participation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47046"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "altered-newport",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "utility-filing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaidevd/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "dfTrain['text'] = dfTrain['text'].map(lambda x: x.decode())\n",
    "xts['text'] = xts['text'].map(lambda x: x.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "placed-delivery",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=len(model.wv))\n",
    "tokenizer.fit_on_texts(dfTrain['text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daily-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(dfTrain['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "chinese-adobe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(xts['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "available-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "demographic-sandwich",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'and': 2,\n",
       " 'a': 3,\n",
       " 'of': 4,\n",
       " 'to': 5,\n",
       " 'is': 6,\n",
       " 'br': 7,\n",
       " 'in': 8,\n",
       " 'it': 9,\n",
       " 'i': 10,\n",
       " 'this': 11,\n",
       " 'that': 12,\n",
       " 'was': 13,\n",
       " 'as': 14,\n",
       " 'for': 15,\n",
       " 'with': 16,\n",
       " 'movie': 17,\n",
       " 'but': 18,\n",
       " 'film': 19,\n",
       " 'on': 20,\n",
       " 'not': 21,\n",
       " 'you': 22,\n",
       " 'are': 23,\n",
       " 'his': 24,\n",
       " 'have': 25,\n",
       " 'he': 26,\n",
       " 'be': 27,\n",
       " 'one': 28,\n",
       " 'all': 29,\n",
       " 'at': 30,\n",
       " 'by': 31,\n",
       " 'an': 32,\n",
       " 'they': 33,\n",
       " 'who': 34,\n",
       " 'so': 35,\n",
       " 'from': 36,\n",
       " 'like': 37,\n",
       " 'her': 38,\n",
       " 'or': 39,\n",
       " 'just': 40,\n",
       " 'about': 41,\n",
       " \"it's\": 42,\n",
       " 'out': 43,\n",
       " 'if': 44,\n",
       " 'has': 45,\n",
       " 'some': 46,\n",
       " 'there': 47,\n",
       " 'what': 48,\n",
       " 'good': 49,\n",
       " 'more': 50,\n",
       " 'when': 51,\n",
       " 'very': 52,\n",
       " 'up': 53,\n",
       " 'no': 54,\n",
       " 'time': 55,\n",
       " 'she': 56,\n",
       " 'even': 57,\n",
       " 'my': 58,\n",
       " 'would': 59,\n",
       " 'which': 60,\n",
       " 'only': 61,\n",
       " 'story': 62,\n",
       " 'really': 63,\n",
       " 'see': 64,\n",
       " 'their': 65,\n",
       " 'had': 66,\n",
       " 'can': 67,\n",
       " 'were': 68,\n",
       " 'me': 69,\n",
       " 'well': 70,\n",
       " 'than': 71,\n",
       " 'we': 72,\n",
       " 'much': 73,\n",
       " 'been': 74,\n",
       " 'bad': 75,\n",
       " 'get': 76,\n",
       " 'will': 77,\n",
       " 'do': 78,\n",
       " 'also': 79,\n",
       " 'into': 80,\n",
       " 'people': 81,\n",
       " 'other': 82,\n",
       " 'first': 83,\n",
       " 'great': 84,\n",
       " 'because': 85,\n",
       " 'how': 86,\n",
       " 'him': 87,\n",
       " 'most': 88,\n",
       " \"don't\": 89,\n",
       " 'made': 90,\n",
       " 'its': 91,\n",
       " 'then': 92,\n",
       " 'way': 93,\n",
       " 'make': 94,\n",
       " 'them': 95,\n",
       " 'too': 96,\n",
       " 'could': 97,\n",
       " 'any': 98,\n",
       " 'movies': 99,\n",
       " 'after': 100,\n",
       " 'think': 101,\n",
       " 'characters': 102,\n",
       " 'watch': 103,\n",
       " 'two': 104,\n",
       " 'films': 105,\n",
       " 'character': 106,\n",
       " 'seen': 107,\n",
       " 'many': 108,\n",
       " 'being': 109,\n",
       " 'life': 110,\n",
       " 'plot': 111,\n",
       " 'never': 112,\n",
       " 'acting': 113,\n",
       " 'little': 114,\n",
       " 'best': 115,\n",
       " 'love': 116,\n",
       " 'over': 117,\n",
       " 'where': 118,\n",
       " 'did': 119,\n",
       " 'show': 120,\n",
       " 'know': 121,\n",
       " 'off': 122,\n",
       " 'ever': 123,\n",
       " 'does': 124,\n",
       " 'better': 125,\n",
       " 'your': 126,\n",
       " 'end': 127,\n",
       " 'still': 128,\n",
       " 'man': 129,\n",
       " 'here': 130,\n",
       " 'these': 131,\n",
       " 'say': 132,\n",
       " 'scene': 133,\n",
       " 'while': 134,\n",
       " 'why': 135,\n",
       " 'scenes': 136,\n",
       " 'go': 137,\n",
       " 'such': 138,\n",
       " 'something': 139,\n",
       " 'through': 140,\n",
       " 'should': 141,\n",
       " 'back': 142,\n",
       " \"i'm\": 143,\n",
       " 'real': 144,\n",
       " 'those': 145,\n",
       " 'watching': 146,\n",
       " 'now': 147,\n",
       " 'though': 148,\n",
       " \"doesn't\": 149,\n",
       " 'years': 150,\n",
       " 'old': 151,\n",
       " 'thing': 152,\n",
       " 'actors': 153,\n",
       " 'work': 154,\n",
       " '10': 155,\n",
       " 'before': 156,\n",
       " 'another': 157,\n",
       " \"didn't\": 158,\n",
       " 'new': 159,\n",
       " 'funny': 160,\n",
       " 'nothing': 161,\n",
       " 'actually': 162,\n",
       " 'makes': 163,\n",
       " 'director': 164,\n",
       " 'look': 165,\n",
       " 'find': 166,\n",
       " 'going': 167,\n",
       " 'few': 168,\n",
       " 'same': 169,\n",
       " 'part': 170,\n",
       " 'again': 171,\n",
       " 'every': 172,\n",
       " 'lot': 173,\n",
       " 'cast': 174,\n",
       " 'us': 175,\n",
       " 'quite': 176,\n",
       " 'down': 177,\n",
       " 'want': 178,\n",
       " 'world': 179,\n",
       " 'things': 180,\n",
       " 'pretty': 181,\n",
       " 'young': 182,\n",
       " 'seems': 183,\n",
       " 'around': 184,\n",
       " 'got': 185,\n",
       " 'horror': 186,\n",
       " 'however': 187,\n",
       " \"can't\": 188,\n",
       " 'fact': 189,\n",
       " 'take': 190,\n",
       " 'big': 191,\n",
       " 'enough': 192,\n",
       " 'long': 193,\n",
       " 'thought': 194,\n",
       " \"that's\": 195,\n",
       " 'both': 196,\n",
       " 'between': 197,\n",
       " 'series': 198,\n",
       " 'give': 199,\n",
       " 'may': 200,\n",
       " 'original': 201,\n",
       " 'own': 202,\n",
       " 'action': 203,\n",
       " \"i've\": 204,\n",
       " 'right': 205,\n",
       " 'without': 206,\n",
       " 'always': 207,\n",
       " 'times': 208,\n",
       " 'comedy': 209,\n",
       " 'point': 210,\n",
       " 'gets': 211,\n",
       " 'must': 212,\n",
       " 'come': 213,\n",
       " 'role': 214,\n",
       " \"isn't\": 215,\n",
       " 'saw': 216,\n",
       " 'almost': 217,\n",
       " 'interesting': 218,\n",
       " 'least': 219,\n",
       " 'family': 220,\n",
       " 'done': 221,\n",
       " \"there's\": 222,\n",
       " 'whole': 223,\n",
       " 'bit': 224,\n",
       " 'music': 225,\n",
       " 'script': 226,\n",
       " 'far': 227,\n",
       " 'making': 228,\n",
       " 'anything': 229,\n",
       " 'guy': 230,\n",
       " 'minutes': 231,\n",
       " 'feel': 232,\n",
       " 'last': 233,\n",
       " 'since': 234,\n",
       " 'might': 235,\n",
       " 'performance': 236,\n",
       " \"he's\": 237,\n",
       " '2': 238,\n",
       " 'probably': 239,\n",
       " 'kind': 240,\n",
       " 'am': 241,\n",
       " 'away': 242,\n",
       " 'yet': 243,\n",
       " 'rather': 244,\n",
       " 'tv': 245,\n",
       " 'worst': 246,\n",
       " 'girl': 247,\n",
       " 'day': 248,\n",
       " 'sure': 249,\n",
       " 'fun': 250,\n",
       " 'hard': 251,\n",
       " 'woman': 252,\n",
       " 'played': 253,\n",
       " 'each': 254,\n",
       " 'found': 255,\n",
       " 'anyone': 256,\n",
       " 'having': 257,\n",
       " 'although': 258,\n",
       " 'especially': 259,\n",
       " 'our': 260,\n",
       " 'believe': 261,\n",
       " 'course': 262,\n",
       " 'comes': 263,\n",
       " 'looking': 264,\n",
       " 'screen': 265,\n",
       " 'trying': 266,\n",
       " 'set': 267,\n",
       " 'goes': 268,\n",
       " 'looks': 269,\n",
       " 'place': 270,\n",
       " 'book': 271,\n",
       " 'different': 272,\n",
       " 'put': 273,\n",
       " 'ending': 274,\n",
       " 'money': 275,\n",
       " 'maybe': 276,\n",
       " 'once': 277,\n",
       " 'sense': 278,\n",
       " 'reason': 279,\n",
       " 'true': 280,\n",
       " 'actor': 281,\n",
       " 'everything': 282,\n",
       " \"wasn't\": 283,\n",
       " 'shows': 284,\n",
       " 'dvd': 285,\n",
       " 'three': 286,\n",
       " 'worth': 287,\n",
       " 'year': 288,\n",
       " 'job': 289,\n",
       " 'main': 290,\n",
       " 'someone': 291,\n",
       " 'together': 292,\n",
       " 'watched': 293,\n",
       " 'play': 294,\n",
       " 'american': 295,\n",
       " 'plays': 296,\n",
       " '1': 297,\n",
       " 'said': 298,\n",
       " 'effects': 299,\n",
       " 'later': 300,\n",
       " 'takes': 301,\n",
       " 'instead': 302,\n",
       " 'seem': 303,\n",
       " 'john': 304,\n",
       " 'beautiful': 305,\n",
       " 'himself': 306,\n",
       " 'version': 307,\n",
       " 'high': 308,\n",
       " 'audience': 309,\n",
       " 'house': 310,\n",
       " 'night': 311,\n",
       " 'during': 312,\n",
       " 'everyone': 313,\n",
       " 'left': 314,\n",
       " 'special': 315,\n",
       " 'seeing': 316,\n",
       " 'half': 317,\n",
       " 'excellent': 318,\n",
       " 'wife': 319,\n",
       " 'star': 320,\n",
       " 'shot': 321,\n",
       " 'war': 322,\n",
       " 'idea': 323,\n",
       " 'nice': 324,\n",
       " 'black': 325,\n",
       " 'less': 326,\n",
       " 'mind': 327,\n",
       " 'simply': 328,\n",
       " 'read': 329,\n",
       " 'second': 330,\n",
       " 'else': 331,\n",
       " \"you're\": 332,\n",
       " 'father': 333,\n",
       " 'fan': 334,\n",
       " 'help': 335,\n",
       " 'poor': 336,\n",
       " 'completely': 337,\n",
       " 'death': 338,\n",
       " '3': 339,\n",
       " 'used': 340,\n",
       " 'home': 341,\n",
       " 'either': 342,\n",
       " 'short': 343,\n",
       " 'line': 344,\n",
       " 'given': 345,\n",
       " 'men': 346,\n",
       " 'top': 347,\n",
       " 'dead': 348,\n",
       " 'budget': 349,\n",
       " 'try': 350,\n",
       " 'performances': 351,\n",
       " 'wrong': 352,\n",
       " 'classic': 353,\n",
       " 'enjoy': 354,\n",
       " 'boring': 355,\n",
       " 'need': 356,\n",
       " 'rest': 357,\n",
       " 'use': 358,\n",
       " 'hollywood': 359,\n",
       " 'kids': 360,\n",
       " 'low': 361,\n",
       " 'production': 362,\n",
       " 'until': 363,\n",
       " 'along': 364,\n",
       " 'full': 365,\n",
       " 'friends': 366,\n",
       " 'camera': 367,\n",
       " 'truly': 368,\n",
       " 'women': 369,\n",
       " 'awful': 370,\n",
       " 'video': 371,\n",
       " 'next': 372,\n",
       " 'tell': 373,\n",
       " 'remember': 374,\n",
       " 'stupid': 375,\n",
       " 'couple': 376,\n",
       " 'start': 377,\n",
       " 'stars': 378,\n",
       " 'perhaps': 379,\n",
       " 'mean': 380,\n",
       " 'sex': 381,\n",
       " 'came': 382,\n",
       " 'recommend': 383,\n",
       " 'let': 384,\n",
       " 'moments': 385,\n",
       " 'wonderful': 386,\n",
       " 'episode': 387,\n",
       " 'understand': 388,\n",
       " 'small': 389,\n",
       " 'face': 390,\n",
       " 'terrible': 391,\n",
       " 'school': 392,\n",
       " 'playing': 393,\n",
       " 'getting': 394,\n",
       " 'written': 395,\n",
       " 'often': 396,\n",
       " 'doing': 397,\n",
       " 'keep': 398,\n",
       " 'early': 399,\n",
       " 'name': 400,\n",
       " 'perfect': 401,\n",
       " 'style': 402,\n",
       " 'human': 403,\n",
       " 'definitely': 404,\n",
       " 'others': 405,\n",
       " 'gives': 406,\n",
       " 'itself': 407,\n",
       " 'lines': 408,\n",
       " 'live': 409,\n",
       " 'become': 410,\n",
       " 'dialogue': 411,\n",
       " 'person': 412,\n",
       " 'lost': 413,\n",
       " 'finally': 414,\n",
       " 'piece': 415,\n",
       " 'head': 416,\n",
       " 'case': 417,\n",
       " 'felt': 418,\n",
       " 'yes': 419,\n",
       " 'supposed': 420,\n",
       " 'liked': 421,\n",
       " 'title': 422,\n",
       " \"couldn't\": 423,\n",
       " 'absolutely': 424,\n",
       " 'white': 425,\n",
       " 'against': 426,\n",
       " 'boy': 427,\n",
       " 'picture': 428,\n",
       " 'sort': 429,\n",
       " 'worse': 430,\n",
       " 'certainly': 431,\n",
       " 'went': 432,\n",
       " 'entire': 433,\n",
       " 'waste': 434,\n",
       " 'cinema': 435,\n",
       " 'problem': 436,\n",
       " 'hope': 437,\n",
       " 'entertaining': 438,\n",
       " \"she's\": 439,\n",
       " 'mr': 440,\n",
       " 'overall': 441,\n",
       " 'evil': 442,\n",
       " 'called': 443,\n",
       " 'loved': 444,\n",
       " 'based': 445,\n",
       " 'oh': 446,\n",
       " 'several': 447,\n",
       " 'fans': 448,\n",
       " 'mother': 449,\n",
       " 'drama': 450,\n",
       " 'beginning': 451,\n",
       " 'killer': 452,\n",
       " 'lives': 453,\n",
       " '5': 454,\n",
       " 'direction': 455,\n",
       " 'care': 456,\n",
       " 'already': 457,\n",
       " 'becomes': 458,\n",
       " 'example': 459,\n",
       " 'laugh': 460,\n",
       " 'friend': 461,\n",
       " 'dark': 462,\n",
       " 'despite': 463,\n",
       " 'under': 464,\n",
       " 'seemed': 465,\n",
       " 'throughout': 466,\n",
       " '4': 467,\n",
       " 'turn': 468,\n",
       " 'unfortunately': 469,\n",
       " 'wanted': 470,\n",
       " \"i'd\": 471,\n",
       " '\\x96': 472,\n",
       " 'children': 473,\n",
       " 'final': 474,\n",
       " 'fine': 475,\n",
       " 'history': 476,\n",
       " 'amazing': 477,\n",
       " 'sound': 478,\n",
       " 'guess': 479,\n",
       " 'heart': 480,\n",
       " 'totally': 481,\n",
       " 'lead': 482,\n",
       " 'humor': 483,\n",
       " 'writing': 484,\n",
       " 'michael': 485,\n",
       " 'quality': 486,\n",
       " \"you'll\": 487,\n",
       " 'close': 488,\n",
       " 'son': 489,\n",
       " 'guys': 490,\n",
       " 'wants': 491,\n",
       " 'works': 492,\n",
       " 'behind': 493,\n",
       " 'tries': 494,\n",
       " 'art': 495,\n",
       " 'side': 496,\n",
       " 'game': 497,\n",
       " 'past': 498,\n",
       " 'able': 499,\n",
       " 'b': 500,\n",
       " 'days': 501,\n",
       " 'turns': 502,\n",
       " \"they're\": 503,\n",
       " 'child': 504,\n",
       " 'hand': 505,\n",
       " 'enjoyed': 506,\n",
       " 'flick': 507,\n",
       " 'act': 508,\n",
       " 'genre': 509,\n",
       " 'town': 510,\n",
       " 'favorite': 511,\n",
       " 'soon': 512,\n",
       " 'kill': 513,\n",
       " 'starts': 514,\n",
       " 'sometimes': 515,\n",
       " 'gave': 516,\n",
       " 'car': 517,\n",
       " 'run': 518,\n",
       " 'late': 519,\n",
       " 'eyes': 520,\n",
       " 'etc': 521,\n",
       " 'actress': 522,\n",
       " 'directed': 523,\n",
       " 'horrible': 524,\n",
       " \"won't\": 525,\n",
       " 'viewer': 526,\n",
       " 'brilliant': 527,\n",
       " 'parts': 528,\n",
       " 'themselves': 529,\n",
       " 'self': 530,\n",
       " 'hour': 531,\n",
       " 'expect': 532,\n",
       " 'thinking': 533,\n",
       " 'stories': 534,\n",
       " 'stuff': 535,\n",
       " 'girls': 536,\n",
       " 'obviously': 537,\n",
       " 'blood': 538,\n",
       " 'decent': 539,\n",
       " 'city': 540,\n",
       " 'voice': 541,\n",
       " 'highly': 542,\n",
       " 'myself': 543,\n",
       " 'feeling': 544,\n",
       " 'fight': 545,\n",
       " 'except': 546,\n",
       " 'slow': 547,\n",
       " 'matter': 548,\n",
       " 'type': 549,\n",
       " 'anyway': 550,\n",
       " 'kid': 551,\n",
       " 'roles': 552,\n",
       " 'killed': 553,\n",
       " 'heard': 554,\n",
       " 'age': 555,\n",
       " 'says': 556,\n",
       " 'god': 557,\n",
       " 'moment': 558,\n",
       " 'took': 559,\n",
       " 'leave': 560,\n",
       " 'writer': 561,\n",
       " 'cannot': 562,\n",
       " 'strong': 563,\n",
       " 'violence': 564,\n",
       " 'police': 565,\n",
       " 'hit': 566,\n",
       " 'happens': 567,\n",
       " 'stop': 568,\n",
       " 'particularly': 569,\n",
       " 'known': 570,\n",
       " 'happened': 571,\n",
       " 'involved': 572,\n",
       " 'extremely': 573,\n",
       " 'daughter': 574,\n",
       " 'obvious': 575,\n",
       " 'told': 576,\n",
       " 'chance': 577,\n",
       " 'living': 578,\n",
       " 'coming': 579,\n",
       " 'lack': 580,\n",
       " 'experience': 581,\n",
       " 'alone': 582,\n",
       " \"wouldn't\": 583,\n",
       " 'including': 584,\n",
       " 'murder': 585,\n",
       " 'attempt': 586,\n",
       " 's': 587,\n",
       " 'please': 588,\n",
       " 'james': 589,\n",
       " 'happen': 590,\n",
       " 'wonder': 591,\n",
       " 'crap': 592,\n",
       " 'ago': 593,\n",
       " 'brother': 594,\n",
       " \"film's\": 595,\n",
       " 'gore': 596,\n",
       " 'complete': 597,\n",
       " 'none': 598,\n",
       " 'interest': 599,\n",
       " 'score': 600,\n",
       " 'group': 601,\n",
       " 'cut': 602,\n",
       " 'simple': 603,\n",
       " 'save': 604,\n",
       " 'hell': 605,\n",
       " 'looked': 606,\n",
       " 'ok': 607,\n",
       " 'number': 608,\n",
       " 'career': 609,\n",
       " 'song': 610,\n",
       " 'possible': 611,\n",
       " 'seriously': 612,\n",
       " 'annoying': 613,\n",
       " 'sad': 614,\n",
       " 'shown': 615,\n",
       " 'exactly': 616,\n",
       " 'running': 617,\n",
       " 'serious': 618,\n",
       " 'musical': 619,\n",
       " 'taken': 620,\n",
       " 'yourself': 621,\n",
       " 'released': 622,\n",
       " 'whose': 623,\n",
       " 'david': 624,\n",
       " 'cinematography': 625,\n",
       " 'scary': 626,\n",
       " 'ends': 627,\n",
       " 'hero': 628,\n",
       " 'usually': 629,\n",
       " 'english': 630,\n",
       " 'hours': 631,\n",
       " 'reality': 632,\n",
       " 'opening': 633,\n",
       " \"i'll\": 634,\n",
       " 'across': 635,\n",
       " 'jokes': 636,\n",
       " 'light': 637,\n",
       " 'today': 638,\n",
       " 'hilarious': 639,\n",
       " 'somewhat': 640,\n",
       " 'usual': 641,\n",
       " 'body': 642,\n",
       " 'started': 643,\n",
       " 'cool': 644,\n",
       " 'ridiculous': 645,\n",
       " 'level': 646,\n",
       " 'relationship': 647,\n",
       " 'view': 648,\n",
       " 'change': 649,\n",
       " 'opinion': 650,\n",
       " 'happy': 651,\n",
       " 'middle': 652,\n",
       " 'taking': 653,\n",
       " 'wish': 654,\n",
       " 'finds': 655,\n",
       " 'husband': 656,\n",
       " 'order': 657,\n",
       " 'saying': 658,\n",
       " 'shots': 659,\n",
       " 'ones': 660,\n",
       " 'documentary': 661,\n",
       " 'talking': 662,\n",
       " 'huge': 663,\n",
       " 'novel': 664,\n",
       " 'female': 665,\n",
       " 'mostly': 666,\n",
       " 'robert': 667,\n",
       " 'power': 668,\n",
       " 'episodes': 669,\n",
       " 'room': 670,\n",
       " 'important': 671,\n",
       " 'rating': 672,\n",
       " 'talent': 673,\n",
       " 'five': 674,\n",
       " 'major': 675,\n",
       " 'strange': 676,\n",
       " 'turned': 677,\n",
       " 'word': 678,\n",
       " 'modern': 679,\n",
       " 'call': 680,\n",
       " 'apparently': 681,\n",
       " 'single': 682,\n",
       " 'disappointed': 683,\n",
       " 'events': 684,\n",
       " 'due': 685,\n",
       " 'four': 686,\n",
       " 'songs': 687,\n",
       " 'attention': 688,\n",
       " 'basically': 689,\n",
       " '7': 690,\n",
       " 'knows': 691,\n",
       " 'knew': 692,\n",
       " 'clearly': 693,\n",
       " 'supporting': 694,\n",
       " 'non': 695,\n",
       " 'british': 696,\n",
       " 'television': 697,\n",
       " 'comic': 698,\n",
       " 'earth': 699,\n",
       " 'fast': 700,\n",
       " 'country': 701,\n",
       " 'future': 702,\n",
       " 'class': 703,\n",
       " 'cheap': 704,\n",
       " '8': 705,\n",
       " 'silly': 706,\n",
       " 'thriller': 707,\n",
       " 'king': 708,\n",
       " 'problems': 709,\n",
       " \"aren't\": 710,\n",
       " 'easily': 711,\n",
       " 'words': 712,\n",
       " 'tells': 713,\n",
       " 'jack': 714,\n",
       " 'miss': 715,\n",
       " 'local': 716,\n",
       " 'sequence': 717,\n",
       " 'bring': 718,\n",
       " 'entertainment': 719,\n",
       " 'paul': 720,\n",
       " 'beyond': 721,\n",
       " 'upon': 722,\n",
       " 'whether': 723,\n",
       " 'moving': 724,\n",
       " 'predictable': 725,\n",
       " 'straight': 726,\n",
       " 'similar': 727,\n",
       " 'sets': 728,\n",
       " 'romantic': 729,\n",
       " 'review': 730,\n",
       " 'oscar': 731,\n",
       " 'falls': 732,\n",
       " 'mystery': 733,\n",
       " 'enjoyable': 734,\n",
       " 'rock': 735,\n",
       " 'talk': 736,\n",
       " 'appears': 737,\n",
       " 'needs': 738,\n",
       " 'george': 739,\n",
       " 'giving': 740,\n",
       " 'eye': 741,\n",
       " 'richard': 742,\n",
       " 'within': 743,\n",
       " 'ten': 744,\n",
       " 'animation': 745,\n",
       " 'message': 746,\n",
       " 'near': 747,\n",
       " 'theater': 748,\n",
       " 'above': 749,\n",
       " 'dull': 750,\n",
       " 'nearly': 751,\n",
       " 'sequel': 752,\n",
       " 'theme': 753,\n",
       " 'points': 754,\n",
       " 'stand': 755,\n",
       " \"'\": 756,\n",
       " 'mention': 757,\n",
       " 'lady': 758,\n",
       " 'bunch': 759,\n",
       " 'add': 760,\n",
       " 'herself': 761,\n",
       " 'feels': 762,\n",
       " 'release': 763,\n",
       " 'red': 764,\n",
       " 'team': 765,\n",
       " 'storyline': 766,\n",
       " 'surprised': 767,\n",
       " 'ways': 768,\n",
       " 'named': 769,\n",
       " 'using': 770,\n",
       " \"haven't\": 771,\n",
       " 'easy': 772,\n",
       " 'lots': 773,\n",
       " 'fantastic': 774,\n",
       " 'begins': 775,\n",
       " 'actual': 776,\n",
       " 'working': 777,\n",
       " 'effort': 778,\n",
       " 'york': 779,\n",
       " 'french': 780,\n",
       " 'die': 781,\n",
       " 'hate': 782,\n",
       " 'minute': 783,\n",
       " 'tale': 784,\n",
       " '9': 785,\n",
       " 'clear': 786,\n",
       " 'stay': 787,\n",
       " 'elements': 788,\n",
       " 'feature': 789,\n",
       " 'among': 790,\n",
       " 'follow': 791,\n",
       " 'comments': 792,\n",
       " 're': 793,\n",
       " 'viewers': 794,\n",
       " 'avoid': 795,\n",
       " 'sister': 796,\n",
       " 'showing': 797,\n",
       " 'typical': 798,\n",
       " 'editing': 799,\n",
       " 'tried': 800,\n",
       " 'famous': 801,\n",
       " \"what's\": 802,\n",
       " 'sorry': 803,\n",
       " 'fall': 804,\n",
       " 'check': 805,\n",
       " 'dialog': 806,\n",
       " 'period': 807,\n",
       " 'form': 808,\n",
       " 'season': 809,\n",
       " 'certain': 810,\n",
       " 'filmed': 811,\n",
       " 'soundtrack': 812,\n",
       " 'weak': 813,\n",
       " 'means': 814,\n",
       " 'material': 815,\n",
       " 'buy': 816,\n",
       " 'realistic': 817,\n",
       " 'somehow': 818,\n",
       " 'crime': 819,\n",
       " 'figure': 820,\n",
       " 'gone': 821,\n",
       " 'doubt': 822,\n",
       " 'peter': 823,\n",
       " 'tom': 824,\n",
       " 'kept': 825,\n",
       " 'viewing': 826,\n",
       " 't': 827,\n",
       " 'general': 828,\n",
       " 'leads': 829,\n",
       " 'greatest': 830,\n",
       " 'space': 831,\n",
       " 'lame': 832,\n",
       " 'suspense': 833,\n",
       " 'dance': 834,\n",
       " 'brought': 835,\n",
       " 'imagine': 836,\n",
       " 'third': 837,\n",
       " 'atmosphere': 838,\n",
       " 'hear': 839,\n",
       " 'particular': 840,\n",
       " 'whatever': 841,\n",
       " 'sequences': 842,\n",
       " 'parents': 843,\n",
       " 'move': 844,\n",
       " 'lee': 845,\n",
       " 'indeed': 846,\n",
       " 'rent': 847,\n",
       " 'de': 848,\n",
       " 'eventually': 849,\n",
       " 'learn': 850,\n",
       " 'note': 851,\n",
       " 'wait': 852,\n",
       " 'average': 853,\n",
       " 'forget': 854,\n",
       " 'deal': 855,\n",
       " 'reviews': 856,\n",
       " 'japanese': 857,\n",
       " 'poorly': 858,\n",
       " 'sexual': 859,\n",
       " 'okay': 860,\n",
       " 'premise': 861,\n",
       " 'surprise': 862,\n",
       " 'zombie': 863,\n",
       " 'stage': 864,\n",
       " 'believable': 865,\n",
       " 'sit': 866,\n",
       " 'possibly': 867,\n",
       " \"who's\": 868,\n",
       " 'decided': 869,\n",
       " 'expected': 870,\n",
       " \"you've\": 871,\n",
       " 'subject': 872,\n",
       " 'nature': 873,\n",
       " 'became': 874,\n",
       " 'free': 875,\n",
       " 'difficult': 876,\n",
       " 'killing': 877,\n",
       " 'screenplay': 878,\n",
       " 'truth': 879,\n",
       " 'romance': 880,\n",
       " 'dr': 881,\n",
       " 'nor': 882,\n",
       " 'reading': 883,\n",
       " 'needed': 884,\n",
       " 'question': 885,\n",
       " 'leaves': 886,\n",
       " 'street': 887,\n",
       " '20': 888,\n",
       " 'meets': 889,\n",
       " 'hot': 890,\n",
       " 'begin': 891,\n",
       " 'unless': 892,\n",
       " 'baby': 893,\n",
       " 'otherwise': 894,\n",
       " 'superb': 895,\n",
       " 'imdb': 896,\n",
       " 'credits': 897,\n",
       " 'write': 898,\n",
       " 'shame': 899,\n",
       " 'situation': 900,\n",
       " \"let's\": 901,\n",
       " 'dramatic': 902,\n",
       " 'memorable': 903,\n",
       " 'earlier': 904,\n",
       " 'directors': 905,\n",
       " 'meet': 906,\n",
       " 'dog': 907,\n",
       " 'open': 908,\n",
       " 'badly': 909,\n",
       " 'disney': 910,\n",
       " 'joe': 911,\n",
       " 'male': 912,\n",
       " 'weird': 913,\n",
       " 'forced': 914,\n",
       " 'acted': 915,\n",
       " 'laughs': 916,\n",
       " 'emotional': 917,\n",
       " 'sci': 918,\n",
       " 'older': 919,\n",
       " 'realize': 920,\n",
       " 'society': 921,\n",
       " 'dream': 922,\n",
       " 'fi': 923,\n",
       " 'writers': 924,\n",
       " 'interested': 925,\n",
       " 'comment': 926,\n",
       " 'forward': 927,\n",
       " 'footage': 928,\n",
       " 'crazy': 929,\n",
       " 'deep': 930,\n",
       " 'america': 931,\n",
       " 'sounds': 932,\n",
       " 'whom': 933,\n",
       " 'plus': 934,\n",
       " 'beauty': 935,\n",
       " 'fantasy': 936,\n",
       " 'directing': 937,\n",
       " 'keeps': 938,\n",
       " 'ask': 939,\n",
       " 'development': 940,\n",
       " 'features': 941,\n",
       " 'quickly': 942,\n",
       " 'air': 943,\n",
       " 'mess': 944,\n",
       " 'creepy': 945,\n",
       " 'towards': 946,\n",
       " 'perfectly': 947,\n",
       " 'mark': 948,\n",
       " 'worked': 949,\n",
       " 'box': 950,\n",
       " 'unique': 951,\n",
       " 'cheesy': 952,\n",
       " 'hands': 953,\n",
       " 'setting': 954,\n",
       " 'plenty': 955,\n",
       " 'result': 956,\n",
       " 'previous': 957,\n",
       " 'brings': 958,\n",
       " 'total': 959,\n",
       " 'effect': 960,\n",
       " 'e': 961,\n",
       " 'personal': 962,\n",
       " 'incredibly': 963,\n",
       " 'fire': 964,\n",
       " 'monster': 965,\n",
       " 'rate': 966,\n",
       " 'business': 967,\n",
       " 'casting': 968,\n",
       " 'apart': 969,\n",
       " 'leading': 970,\n",
       " 'admit': 971,\n",
       " 'powerful': 972,\n",
       " 'joke': 973,\n",
       " 'background': 974,\n",
       " 'appear': 975,\n",
       " 'telling': 976,\n",
       " 'girlfriend': 977,\n",
       " 'meant': 978,\n",
       " 'hardly': 979,\n",
       " 'christmas': 980,\n",
       " 'present': 981,\n",
       " 'battle': 982,\n",
       " 'potential': 983,\n",
       " 'create': 984,\n",
       " 'break': 985,\n",
       " 'bill': 986,\n",
       " 'pay': 987,\n",
       " 'masterpiece': 988,\n",
       " 'political': 989,\n",
       " 'gay': 990,\n",
       " 'return': 991,\n",
       " 'dumb': 992,\n",
       " 'fails': 993,\n",
       " 'fighting': 994,\n",
       " 'various': 995,\n",
       " 'portrayed': 996,\n",
       " 'era': 997,\n",
       " 'co': 998,\n",
       " 'secret': 999,\n",
       " 'cop': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "verbal-terminal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88582"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "agricultural-fairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = max(map(len, train_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "piano-neighbor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2444"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "animated-liquid",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "train_data = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "test_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "above-review",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = dfTrain['label'].values\n",
    "test_labels = xts['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "serious-albuquerque",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "vertical-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "suburban-liberia",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, model.wv.vector_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "southeast-medicaid",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, i in word_index.items():\n",
    "    try:\n",
    "        vector = model.wv.get_vector(word, False)\n",
    "        embedding_matrix[i] = vector\n",
    "    except KeyError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "round-debate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61067"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(embedding_matrix.sum(axis=1) == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "selective-summer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "overall-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "el = Embedding(len(word_index) + 1, model.wv.vector_size, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "demographic-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "proof-judges",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Sequential([\n",
    "    Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32'),\n",
    "    el,\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "apparent-catholic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fantastic-philadelphia",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "vocational-hello",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "196/196 [==============================] - 12s 61ms/step - loss: 0.6926 - accuracy: 0.4985 - val_loss: 0.6921 - val_accuracy: 0.5042\n",
      "Epoch 2/10\n",
      "196/196 [==============================] - 12s 61ms/step - loss: 0.6922 - accuracy: 0.5013 - val_loss: 0.6924 - val_accuracy: 0.5038\n",
      "Epoch 3/10\n",
      "196/196 [==============================] - 12s 61ms/step - loss: 0.6921 - accuracy: 0.5012 - val_loss: 0.6921 - val_accuracy: 0.5044\n",
      "Epoch 4/10\n",
      "196/196 [==============================] - 12s 61ms/step - loss: 0.6921 - accuracy: 0.5051 - val_loss: 0.6922 - val_accuracy: 0.5045\n",
      "Epoch 5/10\n",
      "196/196 [==============================] - 12s 61ms/step - loss: 0.6920 - accuracy: 0.5036 - val_loss: 0.6921 - val_accuracy: 0.5044\n",
      "Epoch 6/10\n",
      "196/196 [==============================] - 12s 61ms/step - loss: 0.6921 - accuracy: 0.5062 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 7/10\n",
      "196/196 [==============================] - 12s 61ms/step - loss: 0.6920 - accuracy: 0.5038 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 8/10\n",
      "196/196 [==============================] - 12s 61ms/step - loss: 0.6920 - accuracy: 0.4995 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 9/10\n",
      "196/196 [==============================] - 12s 61ms/step - loss: 0.6920 - accuracy: 0.5059 - val_loss: 0.6920 - val_accuracy: 0.5045\n",
      "Epoch 10/10\n",
      "196/196 [==============================] - 12s 61ms/step - loss: 0.6920 - accuracy: 0.5042 - val_loss: 0.6920 - val_accuracy: 0.5046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe3e848ac90>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_data, train_labels, validation_data=(test_data, test_labels), epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "rapid-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "selected-stage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = el(sequence_input)\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(35)(x)  # global max pooling\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "false-scanning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "196/196 [==============================] - 12s 61ms/step - loss: 0.6919 - accuracy: 0.5028 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 2/100\n",
      "196/196 [==============================] - 12s 61ms/step - loss: 0.6919 - accuracy: 0.5024 - val_loss: 0.6922 - val_accuracy: 0.5043\n",
      "Epoch 3/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6919 - accuracy: 0.5052 - val_loss: 0.6920 - val_accuracy: 0.5050\n",
      "Epoch 4/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6919 - accuracy: 0.5027 - val_loss: 0.6921 - val_accuracy: 0.5051\n",
      "Epoch 5/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6919 - accuracy: 0.5027 - val_loss: 0.6920 - val_accuracy: 0.5047\n",
      "Epoch 6/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6919 - accuracy: 0.4967 - val_loss: 0.6920 - val_accuracy: 0.5052\n",
      "Epoch 7/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6919 - accuracy: 0.5061 - val_loss: 0.6920 - val_accuracy: 0.5052\n",
      "Epoch 8/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6919 - accuracy: 0.5023 - val_loss: 0.6920 - val_accuracy: 0.5050\n",
      "Epoch 9/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6919 - accuracy: 0.5041 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 10/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5063 - val_loss: 0.6923 - val_accuracy: 0.5043\n",
      "Epoch 11/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6919 - accuracy: 0.5064 - val_loss: 0.6920 - val_accuracy: 0.5047\n",
      "Epoch 12/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6919 - accuracy: 0.5050 - val_loss: 0.6921 - val_accuracy: 0.5051\n",
      "Epoch 13/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6919 - accuracy: 0.5038 - val_loss: 0.6920 - val_accuracy: 0.5052\n",
      "Epoch 14/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5030 - val_loss: 0.6921 - val_accuracy: 0.5046\n",
      "Epoch 15/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5013 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 16/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6919 - accuracy: 0.5022 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 17/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5039 - val_loss: 0.6921 - val_accuracy: 0.5051\n",
      "Epoch 18/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5003 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 19/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5010 - val_loss: 0.6920 - val_accuracy: 0.5050\n",
      "Epoch 20/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5029 - val_loss: 0.6921 - val_accuracy: 0.5051\n",
      "Epoch 21/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.4993 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 22/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5018 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 23/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5049 - val_loss: 0.6920 - val_accuracy: 0.5047\n",
      "Epoch 24/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5058 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 25/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5032 - val_loss: 0.6920 - val_accuracy: 0.5052\n",
      "Epoch 26/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5056 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 27/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5024 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 28/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5032 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 29/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5015 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 30/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5050 - val_loss: 0.6921 - val_accuracy: 0.5051\n",
      "Epoch 31/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5055 - val_loss: 0.6920 - val_accuracy: 0.5047\n",
      "Epoch 32/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5034 - val_loss: 0.6921 - val_accuracy: 0.5051\n",
      "Epoch 33/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5050 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 34/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5061 - val_loss: 0.6920 - val_accuracy: 0.5047\n",
      "Epoch 35/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5069 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 36/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5056 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 37/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5052 - val_loss: 0.6921 - val_accuracy: 0.5051\n",
      "Epoch 38/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5029 - val_loss: 0.6921 - val_accuracy: 0.5051\n",
      "Epoch 39/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5046 - val_loss: 0.6921 - val_accuracy: 0.5051\n",
      "Epoch 40/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5038 - val_loss: 0.6920 - val_accuracy: 0.5052\n",
      "Epoch 41/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5056 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 42/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5042 - val_loss: 0.6921 - val_accuracy: 0.5050\n",
      "Epoch 43/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5004 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 44/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5039 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 45/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5037 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 46/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5030 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 47/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.4990 - val_loss: 0.6921 - val_accuracy: 0.5046\n",
      "Epoch 48/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5045 - val_loss: 0.6920 - val_accuracy: 0.5047\n",
      "Epoch 49/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5006 - val_loss: 0.6920 - val_accuracy: 0.5047\n",
      "Epoch 50/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5049 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 51/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5011 - val_loss: 0.6920 - val_accuracy: 0.5052\n",
      "Epoch 52/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.4992 - val_loss: 0.6920 - val_accuracy: 0.5052\n",
      "Epoch 53/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5059 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 54/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5016 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 55/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5043 - val_loss: 0.6921 - val_accuracy: 0.5051\n",
      "Epoch 56/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6917 - accuracy: 0.5032 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 57/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5012 - val_loss: 0.6920 - val_accuracy: 0.5046\n",
      "Epoch 58/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6917 - accuracy: 0.5076 - val_loss: 0.6921 - val_accuracy: 0.5051\n",
      "Epoch 59/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5056 - val_loss: 0.6920 - val_accuracy: 0.5052\n",
      "Epoch 60/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5040 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 61/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6917 - accuracy: 0.5068 - val_loss: 0.6921 - val_accuracy: 0.5046\n",
      "Epoch 62/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5026 - val_loss: 0.6920 - val_accuracy: 0.5046\n",
      "Epoch 63/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5015 - val_loss: 0.6921 - val_accuracy: 0.5046\n",
      "Epoch 64/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5039 - val_loss: 0.6921 - val_accuracy: 0.5051\n",
      "Epoch 65/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6917 - accuracy: 0.5022 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 66/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6917 - accuracy: 0.5038 - val_loss: 0.6920 - val_accuracy: 0.5047\n",
      "Epoch 67/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6917 - accuracy: 0.5033 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 68/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6917 - accuracy: 0.5019 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 69/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6917 - accuracy: 0.5055 - val_loss: 0.6921 - val_accuracy: 0.5046\n",
      "Epoch 70/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5019 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 71/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6917 - accuracy: 0.5029 - val_loss: 0.6921 - val_accuracy: 0.5050\n",
      "Epoch 72/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6918 - accuracy: 0.5026 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 73/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6917 - accuracy: 0.5028 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 74/100\n",
      "196/196 [==============================] - 12s 61ms/step - loss: 0.6917 - accuracy: 0.5029 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 75/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6917 - accuracy: 0.4996 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 76/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6917 - accuracy: 0.5035 - val_loss: 0.6921 - val_accuracy: 0.5051\n",
      "Epoch 77/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6917 - accuracy: 0.5034 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 78/100\n",
      "196/196 [==============================] - 12s 61ms/step - loss: 0.6917 - accuracy: 0.5024 - val_loss: 0.6921 - val_accuracy: 0.5051\n",
      "Epoch 79/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6917 - accuracy: 0.5033 - val_loss: 0.6921 - val_accuracy: 0.5051\n",
      "Epoch 80/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6917 - accuracy: 0.4990 - val_loss: 0.6921 - val_accuracy: 0.5051\n",
      "Epoch 81/100\n",
      "196/196 [==============================] - 12s 61ms/step - loss: 0.6917 - accuracy: 0.5038 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 82/100\n",
      "196/196 [==============================] - 12s 61ms/step - loss: 0.6917 - accuracy: 0.5057 - val_loss: 0.6920 - val_accuracy: 0.5047\n",
      "Epoch 83/100\n",
      "196/196 [==============================] - 12s 61ms/step - loss: 0.6917 - accuracy: 0.5002 - val_loss: 0.6921 - val_accuracy: 0.5051\n",
      "Epoch 84/100\n",
      "196/196 [==============================] - 12s 61ms/step - loss: 0.6917 - accuracy: 0.5006 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 85/100\n",
      "196/196 [==============================] - 12s 61ms/step - loss: 0.6917 - accuracy: 0.5029 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 86/100\n",
      "196/196 [==============================] - 12s 61ms/step - loss: 0.6917 - accuracy: 0.5035 - val_loss: 0.6921 - val_accuracy: 0.5051\n",
      "Epoch 87/100\n",
      "196/196 [==============================] - 12s 61ms/step - loss: 0.6917 - accuracy: 0.5049 - val_loss: 0.6921 - val_accuracy: 0.5051\n",
      "Epoch 88/100\n",
      "196/196 [==============================] - 12s 61ms/step - loss: 0.6917 - accuracy: 0.5038 - val_loss: 0.6921 - val_accuracy: 0.5051\n",
      "Epoch 89/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6917 - accuracy: 0.5033 - val_loss: 0.6920 - val_accuracy: 0.5046\n",
      "Epoch 90/100\n",
      "196/196 [==============================] - 12s 61ms/step - loss: 0.6917 - accuracy: 0.5035 - val_loss: 0.6921 - val_accuracy: 0.5051\n",
      "Epoch 91/100\n",
      "196/196 [==============================] - 12s 61ms/step - loss: 0.6917 - accuracy: 0.5036 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 92/100\n",
      "196/196 [==============================] - 12s 61ms/step - loss: 0.6917 - accuracy: 0.5044 - val_loss: 0.6921 - val_accuracy: 0.5051\n",
      "Epoch 93/100\n",
      "196/196 [==============================] - 12s 61ms/step - loss: 0.6917 - accuracy: 0.5019 - val_loss: 0.6920 - val_accuracy: 0.5047\n",
      "Epoch 94/100\n",
      "196/196 [==============================] - 12s 61ms/step - loss: 0.6917 - accuracy: 0.5013 - val_loss: 0.6920 - val_accuracy: 0.5047\n",
      "Epoch 95/100\n",
      "196/196 [==============================] - 12s 61ms/step - loss: 0.6917 - accuracy: 0.5044 - val_loss: 0.6920 - val_accuracy: 0.5046\n",
      "Epoch 96/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6917 - accuracy: 0.5058 - val_loss: 0.6920 - val_accuracy: 0.5051\n",
      "Epoch 97/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6917 - accuracy: 0.5042 - val_loss: 0.6920 - val_accuracy: 0.5052\n",
      "Epoch 98/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6917 - accuracy: 0.5059 - val_loss: 0.6921 - val_accuracy: 0.5046\n",
      "Epoch 99/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6917 - accuracy: 0.5030 - val_loss: 0.6921 - val_accuracy: 0.5051\n",
      "Epoch 100/100\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 0.6917 - accuracy: 0.5013 - val_loss: 0.6920 - val_accuracy: 0.5051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe4659dca50>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_data, train_labels, validation_data=(test_data, test_labels), epochs=100, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-conflict",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
