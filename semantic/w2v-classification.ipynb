{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "actual-tanzania",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from tensorflow.keras.preprocessing import text_dataset_from_directory\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "vital-native",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format('data/glove.6B.300d.txt', no_header=True, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cloudy-extent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19997 texts.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "TEXT_DATA_DIR = 'data/20_newsgroup'\n",
    "\n",
    "texts = []  # list of text samples\n",
    "labels_index = {}  # dictionary mapping label name to numeric id\n",
    "labels = []  # list of label ids\n",
    "for name in sorted(os.listdir(TEXT_DATA_DIR)):\n",
    "    path = os.path.join(TEXT_DATA_DIR, name)\n",
    "    if os.path.isdir(path):\n",
    "        label_id = len(labels_index)\n",
    "        labels_index[name] = label_id\n",
    "        for fname in sorted(os.listdir(path)):\n",
    "            if fname.isdigit():\n",
    "                fpath = os.path.join(path, fname)\n",
    "                if sys.version_info < (3,):\n",
    "                    f = open(fpath)\n",
    "                else:\n",
    "                    f = open(fpath, encoding='latin-1')\n",
    "                t = f.read()\n",
    "                i = t.find('\\n\\n')  # skip header\n",
    "                if 0 < i:\n",
    "                    t = t[i:]\n",
    "                texts.append(t)\n",
    "                f.close()\n",
    "                labels.append(label_id)\n",
    "\n",
    "print('Found %s texts.' % len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "saving-disco",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 174074 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "affected-bracket",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = max(map(len, sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "played-services",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (19997, 39726)\n",
      "Shape of label tensor: (19997, 20)\n"
     ]
    }
   ],
   "source": [
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "labels = to_categorical(np.asarray(labels))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "# split the data into a training set and a validation set\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "nb_validation_samples = int(0.25 * data.shape[0])\n",
    "\n",
    "x_train = data[:-nb_validation_samples]\n",
    "y_train = labels[:-nb_validation_samples]\n",
    "x_val = data[-nb_validation_samples:]\n",
    "y_val = labels[-nb_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eastern-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = make_embedding_layer(model, tokenizer, MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "charming-advancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "em_out = embedding_layer(x_train[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dated-headquarters",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 39726, 300])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "whole-window",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_out = Conv1D(128, 5, activation='relu')(em_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "centered-testing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 39722, 128])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "understanding-spank",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxp1_out = MaxPooling1D(5)(conv1_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bored-burning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 7944, 128])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxp1_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "approximate-explorer",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2_out = Conv1D(128, 5, activation='relu')(maxp1_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "handy-acting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 7940, 128])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "proprietary-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxp2_out = MaxPooling1D(5)(conv2_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fifth-daughter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 1588, 128])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxp2_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "loose-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv3_out = Conv1D(128, 5, activation='relu')(maxp2_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "biblical-security",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 1584, 128])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv3_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "derived-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxp3_out = MaxPooling1D(35)(conv3_out)  # global max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "hungry-fairy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 45, 128])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxp3_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "deadly-bread",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_out = Flatten()(maxp3_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "joint-filing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 5760])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "exempt-zoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import GlobalAveragePooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "visible-sandwich",
   "metadata": {},
   "outputs": [],
   "source": [
    "globav = GlobalAveragePooling1D()(em_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "particular-index",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 300])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globav.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-israeli",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
