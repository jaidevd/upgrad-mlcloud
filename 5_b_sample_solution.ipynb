{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/ames/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a visual look at the data. What does out target column look like?\n",
    "df['SalePrice'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know that the number of rooms affects the price of the house. Does that hold true here as well?\n",
    "# (One of the variables that denotes rooms is `TotRmsAbvGrd`, i.e. total number of rooms above the ground floor,\n",
    "#  except the bathrooms)\n",
    "# What about the living area?\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "df.plot(x='TotRmsAbvGrd', y='SalePrice', kind='scatter', ax=ax[0])\n",
    "df.plot(x='GrLivArea', y='SalePrice', kind='scatter', ax=ax[1])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check which columns are numerical, and which are categorical.\n",
    "# No choice but to read the documentation ;)\n",
    "# (But we can do a little hack!)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "\n",
    "df['MSSubClass'].hist(bins=20, ax=ax[0])\n",
    "ax[0].set_title('Histogram of MSSubClass')\n",
    "\n",
    "df['LotFrontage'].hist(bins=50, ax=ax[1])\n",
    "ax[1].set_title('Histogram of street area around property')\n",
    "\n",
    "# Unfortunately this doesn't always work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is going to take time, be patient.\n",
    "categoricalCols = ['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities',\n",
    "                   'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
    "                   'HouseStyle', 'OverallQual', 'OverallCond', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
    "                   'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n",
    "                   'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir',\n",
    "                   'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish',\n",
    "                   'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType',\n",
    "                   'SaleCondition']\n",
    "numericalCols  = ['LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
    "                  'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr',\n",
    "                  'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea', 'WoodDeckSF',\n",
    "                  'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we train on the numerical columns only?\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning - categorical columns may contain mixed types!\n",
    "for c in categoricalCols:\n",
    "    df[c] = df[c].astype(str)\n",
    "    df[c].fillna(value=\"\", inplace=True)\n",
    "\n",
    "sdf = spark.createDataFrame(df)\n",
    "numericalDataset = sdf.select(*numericalCols + ['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=[c for c in numericalDataset.columns if c != 'SalePrice'],\n",
    "                            outputCol='features', handleInvalid='skip')\n",
    "numDataset = assembler.transform(numericalDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat this a few times - God doesn't play dice but we have to.\n",
    "\n",
    "trainData, testData = numDataset.randomSplit([0.7, 0.3])\n",
    "\n",
    "lr = LinearRegression(featuresCol='features', labelCol='SalePrice')\n",
    "model = lr.fit(trainData)\n",
    "\n",
    "summary = model.evaluate(testData)\n",
    "summary.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we do better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterDataset = sdf\n",
    "\n",
    "for c in categoricalCols:\n",
    "    indexer = StringIndexer(inputCol=c, outputCol=c+'Index')\n",
    "    model = indexer.fit(masterDataset)\n",
    "    masterDataset = model.transform(masterDataset)\n",
    "    \n",
    "    ohe = OneHotEncoder(inputCol=c+'Index', outputCol=c+'CategoryVec')\n",
    "    encoder = ohe.fit(masterDataset)\n",
    "    masterDataset = encoder.transform(masterDataset)\n",
    "\n",
    "inputCols = [c + 'CategoryVec' for c in categoricalCols] + numericalCols\n",
    "outputCol = 'features'\n",
    "\n",
    "assembler = VectorAssembler(inputCols=inputCols, outputCol=outputCol, handleInvalid='skip')\n",
    "finalDataset = assembler.transform(masterDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData, testData = finalDataset.randomSplit([0.7, 0.3])\n",
    "\n",
    "lr = LinearRegression(featuresCol='features', labelCol='SalePrice')\n",
    "model = lr.fit(trainData)\n",
    "\n",
    "summary = model.evaluate(testData)\n",
    "summary.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pick lambda for L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "valid_lambdas = np.logspace(-2, 2, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_r2 = []\n",
    "test_r2 = []\n",
    "train, test = finalDataset.randomSplit([0.7, 0.3])\n",
    "\n",
    "for l in valid_lambdas:    \n",
    "    lr = LinearRegression(featuresCol='features', labelCol='SalePrice', elasticNetParam=0, regParam=l)\n",
    "    model = lr.fit(train)\n",
    "\n",
    "    # Evaluate on training data\n",
    "    summary_train = model.evaluate(train)\n",
    "    train_r2.append(summary_train.r2)\n",
    "\n",
    "    # Evaluate on training data\n",
    "    summary_test = model.evaluate(test)\n",
    "    test_r2.append(summary_test.r2)\n",
    "\n",
    "    \n",
    "plt.plot(valid_lambdas, train_r2, 'ro-', label='train')\n",
    "plt.plot(valid_lambdas, test_r2, 'go-', label='test')\n",
    "plt.xlabel('$\\lambda$')\n",
    "plt.ylabel('R2')\n",
    "plt.xscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to change lambda search and run this again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_lambdas = np.linspace(0, 10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_r2 = []\n",
    "test_r2 = []\n",
    "train, test = finalDataset.randomSplit([0.7, 0.3])\n",
    "\n",
    "for l in valid_lambdas:    \n",
    "    lr = LinearRegression(featuresCol='features', labelCol='SalePrice', elasticNetParam=1, regParam=l)\n",
    "    model = lr.fit(train)\n",
    "\n",
    "    # Evaluate on training data\n",
    "    summary_train = model.evaluate(train)\n",
    "    train_r2.append(summary_train.r2)\n",
    "\n",
    "    # Evaluate on training data\n",
    "    summary_test = model.evaluate(test)\n",
    "    test_r2.append(summary_test.r2)\n",
    "\n",
    "    \n",
    "plt.plot(valid_lambdas, train_r2, 'ro-', label='train')\n",
    "plt.plot(valid_lambdas, test_r2, 'go-', label='test')\n",
    "plt.xlabel('$\\lambda$')\n",
    "plt.ylabel('R2')\n",
    "plt.xscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(np.array(model.coefficients)).hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
